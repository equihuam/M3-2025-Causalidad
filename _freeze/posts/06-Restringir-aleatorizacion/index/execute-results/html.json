{
  "hash": "7ab1c6d6239599b604587f1a433cccd6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Restricciones a la aleatorización\"\nauthor: [\"Miguel Equihua\", \"Elio Lagunes\"]\ndate: \"2025-01-31\"\nlang: es\ndraft: true\ncategories: [clase]\nformat:\n  html:\n    code-fold: true\n---\n\n\n\n\n\n![](images/2012-AJ-12-10.jpg){width=\"500\"}\n\n### Restricciones a la aleatorización\n\nImaginemos que tenemos las dos situaciones experimentales que se ilustran en la figura. El análisis de estas situaciones experimentales sugiere dos posible aproximaciones, aproximaciones prácticas, pero\n\n[**¿qué modelos propondrías para analizarlos?**]{style=\"color:GoldenRod\"}\n\n![](images/retricciones_a_la_aleatorizaci%C3%B3n_1.png)\n\nSi se supone ausencia de interacción entre Z y β, ambos casos se podría analizar con el mismo modelo:\n\n$$\ny_{ijk} = \\mu + Z_{i} + B_{j} + \\varepsilon_{k(ij)}\n$$\n\nEn donde: \\* $\\mu$ es la media general \\* $Z_{i}$ es el efecto del tratamiento $i,\\dots, t$ \\* $B_{j}$ es el efecto del tratamiento $j,\\dots, b$ \\* $\\varepsilon_{(ij)}$ es el error aleatorio\n\n### Errores de restricción a la aleatorización\n\nAnderson (1970, 1974) notó que no podía ser que el mismo modelo fuera apropiado para dos situaciones tan distintas. Razonó que no se podían hacer inferencias sobre los **bloques** pues cada uno de ellos aparece sólo una vez.\n\n[**¿Concuerdas en que no es posible estimar su efecto?**]{style=\"color:GoldenRod\"}\n\n[**¿Cuál es el efecto de restringir la aleatorización en la asignación de los tratamientos?**]{style=\"color:GoldenRod\"}.\n\nAnderson propuso incorporar en el modelo términos que dieran cuenta de restricciones en la aleatorización de las unidades experimentales. Llamó a estos términos \"errores de restricción\", pues también sugirió que deberían ser considerados términos de *efectos aleatorios*.\n\nAsí, el modelo de bloques se escribiría así:\n\n$$\ny_{ijkm} = \\mu + Z_{i} + B_{j} + \\delta_{k(j)} + \\varepsilon_{m(ijk)}\n$$\n\nEn donde los términos tienen la misma interpretación de arriba, y lo que agregamos es:\n\n-   $\\delta_{k(j)}$ , el componente de variación aleatoria introducido por la restricción a la aleatorización al formar bloques. Este error por lo pronto no es estimable.\n\n-   $\\varepsilon_{m(ijk)}$ es el componente aleatorio derivado de la precisión de las mediciones.\n\nEl *error de restricción de bloques* representa las características particulares y aleatorias de cada conjunto de unidades que formen el bloque *j* (cosas como errores de medición, condiciones ambientales peculiares del bloque pero comunes en su interior, manipulación común al iinterior del bloque, etc.). Este nuevo término tiene estas características:\n\n-   Es aleatorio (se asume se distribuye como una normal e independientemente: \\~normal(0, $\\sigma_{k}^2$)\n\n-   No es estimable y tampoco lo son sus combinaciones, porque no hay grados de libertad.\n\n-   Es útil en el modelo para facilitar identificar qué efectos se pueden poner a prueba mediante razones *F*. Esto se determina al examinar las *esperanzas de cuadrados medios* (**ECM**).\n\n-   Es un *efecto confundido* (no se puede separar) del efecto de bloque o grupo de unidades experimentales.\n\n¿Cómo se ve el análisis del modelo en un cuadro de ANOVA?\n\n![](images/Anova_caso_1.png)\n\n[¿Qué tipo de efecto tienen los factores? ¿Qué se puede probar comparando cuadrados medios?]{style=\"color:GoldenRod\"}\n\nCon la propuesta de Anderson de incluir términos para representar el efecto de no aplicar aleatorización en forma completa, el cuadro de ANOVA se vería como se muestra enseguida. Hay que notar que en esta argumentación de Anderson, se está considerando un modelo en el que el término de interacción no se incluye. Esto hace que su efecto quede confundido con el error de medición, pero más importante, en el análisis de la varianza, este termino que incluye la estimación confundida de la interacción más la del error de medición, se convierte en el denominador para las pruebas de *F* . Por esta misma razón, los grados de libertad corresponden a los de la interacción, es decir el producto de los grados de libertad de los factores involucrados en la interacción.\n\n[¿Qué tipo de efecto tienen los factores? ¿Qué se puede probar]{style=\"color:GoldenRod\"}\n\n![](Images/Anova_Anderson.png)\n\nLa idea de Anderson tiene validez general para experimentos *completos y balanceados*. Se puede utilizar para analizar con claridad el efecto de distintos arreglos experimentales que puedan interesar al investigador.\n\n#### Ejemplo de aplicación del error de restricción en la planeación de experimentos\n\n![](images/becerro.jpg){width=\"400\"}\n\nSe quieren probar 3 tipos de *ración de alimentación* (**A**, **B**, **C**), sobre el desempeño de vacas de la raza Holstein. Se dispone de 12 animales para realizar el ensayo. Se cuenta con corrales en los que caben hasta 4 animales en cada uno. Podemos optar por dar un tratamiento de alimentación a cada corral.\n\n![](Images/Dise%C3%B1o_vacas_1.png)\n\n[¿Consideras que hay algún inconvenientes en esta situación experimental?]{style=\"color:GoldenRod\"}\n\nEl modelo que razonablemente describe esta situación sería:\n\n$$\nY_{ijk} =  \\mu + T_{i} + \\delta_{j(i)} + \\varepsilon_{k(ij)}\n$$\n\nEl cuadro de ANOVA se vería así:\n\n![](Images/ANOVA_Modelo_vacas_1.png)\n\nLas reglas para el cálculo de los grados de libertad es la siguiente:\n\n1.  Para los términos entre paréntesis (componentes anidados en el diseño), multiplica los niveles que correspondan a los índices.\n2.  Para los términos fuera de paréntesis (componentes cruzados), multiplica (niveles-1) que correspondan a cada índice\n3.  Finalmente, multiplica los dos productos anteriores para obtener los grados de libertad correspondientes al componente de varianza.\n4.  Los grados de libertad de la varianza total es simplemente el número de unidades experimentales (o de observación) menos uno o la suma de los grados de libertad de todas las fuentes de variación consideradas, lo que permite tener una validación sencilla.\n\nAsí, en el caso que estamos viendo los números involucradas con este diseño son: raciones = 3 (índice *i*), Número de corrales por tratamiento = 1 (índice *k*) y finalmente vacas por corral= 4 (índice *j*). En estos términos:\n\n$$\n\\begin{align}\ngl_{ración} &= i - 1 = 2 \\\\\ngl_{corrales} &= (k - 1) \\times i = 0 \\\\\ngl_{ración} &= (j - 1) \\times i \\times k = 9  \\\\\ngl_{total} &= gl_{ración} + gl_{ración} + gl_{ración} = 11\n\\end{align}\n$$\n\n[¿Qué piensan de este otro arreglo experimental?]{style=\"color:GoldenRod\"}\n\n![](Images/Dise%C3%B1o_vacas_2.png)\n\nLa situación ahora es, cada *ración* la asigno a un corral en el que tengo dos animales, y repito todo el experimento considerando los corrales una vez. Esto implica que los corrales, representados por $\\delta$, influirán sobre las vacas que tienen dentro con dos cosas: 1) el efecto del tratamiento y 2) el efecto de las características peculiares del corral. Para controlar estas últimas lo que habría que hacer es **aleatorizar** los corrales entre las *raciones*. Para no introducir un error particular para los animales, habrá que **aleatorizar** las vacas entre los corrales. De esta manera, los efectos de sus peculiaridades se convierten en variaciones aleatorias, independientes que se traducen en el error de ´medición o *residual*.\n\nEl modelo es el mismo que en la situación anterior, pero ahora varían los términos estimables:\n\n$$\nY_{ijk} =  \\mu + T_{i} + \\delta_{j(i)} + \\varepsilon_{k(ij)}\n$$\n\nEl cuadro de ANOVA se vería así:\n\n![](Images/ANOVA_Modelo_vacas_2.png)\n\nLos números de entidades involucradas con este diseño son: raciones = 3 (índice *i*), vacas por corral = 2 (índice *k*) y finalmente repeticiones del experimento completo = 2 (índice *j*):\n\n$$\n\\begin{align}\ngl_{ración} &= i - 1 = 2 \\\\\ngl_{corrales} &= (k - 1) \\times i = 3 \\\\\ngl_{ración} &= (j - 1) \\times i \\times k = 6  \\\\\ngl_{total} &= gl_{ración} + gl_{ración} + gl_{ración} = 11\n\\end{align}\n$$\n\nComo [referencia sugerida encontré este artículo](http://www.scielo.org.co/pdf/rccp/v20n2/v20n2a11.pdf) que describe como hacer el análisis necesario para determinar las *esperanzas de cuadrados medios* (**EMC**).\n\n## Manos\n\nConsidera que estamos midiendo la mano izquierda y la derecha de varios individuos, las medidas están emparejadas dentro de cada individuo. Es decir, queremos controlar estadísticamente las diferencias entre individuos, así nos aseguramos que la mano izquierda del *individuo A* sea analizada en conjunto con la mano derecha del *individuo A*, ya que suponemos que alguien con una mano izquierda grande tendrá una mano derecha grande. Por lo tanto, la variable *Individuo* se incluirá en el modelo como una variable aleatoria. Se podría pensar que cada Individuo representa un **bloque** que incluye una medida para la mano izquierda y una medida para la mano derecha.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(stringr)\nurl_manos <- \"https://drive.google.com/file/d/1GSQMbbX7szydnIMDkWYDBlFBWqTdkC4k/view?usp=drive_link\"\ndat_manos_id <- str_extract(url_manos, \"(?<=d/)(.*)(?=/view)\")\n\nurl_drive <- \"https://docs.google.com/uc?id=%s&export=download\" \nmanos <- read.csv(sprintf(url_drive, dat_manos_id)) \n\n\n#manos <- read.table(\"manos.dat\", sep = \",\", header = T, stringsAsFactors = T)\nhead(manos)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Individual Hand Length\n1          A Left   17.5\n2          B Left   18.4\n3          C Left   16.2\n4          D Left   14.5\n5          E Left   13.5\n6          F Left   18.9\n```\n\n\n:::\n:::\n\n\n\n\n\n### Inspección de los datos\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntapply(manos$Length, list(manos$Hand, manos$Individual), mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         A    B    C    D    E    F    G    H    I    J    K    L    M    N\nLeft  17.5 18.4 16.2 14.5 13.5 18.9 19.5 21.1 17.8 16.8 18.4 17.3 18.9 16.4\nRight 17.6 18.5 15.9 14.9 13.7 18.9 19.5 21.5 18.5 17.1 18.9 17.5 19.5 16.5\n         O    P\nLeft  17.5 15.0\nRight 17.4 15.6\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ninteraction.plot(manos$Individual,manos$Hand, manos$Length)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmanos_modelo_1 <- lm(Length ~ 1, data = manos)\nsummary(manos_modelo_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Length ~ 1, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.975 -1.125  0.025  1.425  4.025 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  17.4750     0.3415   51.16   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.932 on 31 degrees of freedom\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmanos_modelo_2 <- lm(Length ~ Hand, data = manos)\nsummary(manos_modelo_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Length ~ Hand, data = manos)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.894 -1.109  0.075  1.306  3.906 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  17.3562     0.4900  35.418   <2e-16 ***\nHandRight     0.2375     0.6930   0.343    0.734    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.96 on 30 degrees of freedom\nMultiple R-squared:  0.003899,\tAdjusted R-squared:  -0.0293 \nF-statistic: 0.1174 on 1 and 30 DF,  p-value: 0.7342\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmanos_modelo_3 <- lm(Length ~ Hand + Individual, data = manos)\nsummary(manos_modelo_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Length ~ Hand + Individual, data = manos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.26875 -0.09062  0.00000  0.09062  0.26875 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17.43125    0.14440 120.714  < 2e-16 ***\nHandRight    0.23750    0.07004   3.391 0.004034 ** \nIndividualB  0.90000    0.19812   4.543 0.000389 ***\nIndividualC -1.50000    0.19812  -7.571 1.69e-06 ***\nIndividualD -2.85000    0.19812 -14.386 3.50e-10 ***\nIndividualE -3.95000    0.19812 -19.938 3.30e-12 ***\nIndividualF  1.35000    0.19812   6.814 5.85e-06 ***\nIndividualG  1.95000    0.19812   9.843 6.15e-08 ***\nIndividualH  3.75000    0.19812  18.928 7.00e-12 ***\nIndividualI  0.60000    0.19812   3.029 0.008466 ** \nIndividualJ -0.60000    0.19812  -3.029 0.008466 ** \nIndividualK  1.10000    0.19812   5.552 5.54e-05 ***\nIndividualL -0.15000    0.19812  -0.757 0.460699    \nIndividualM  1.65000    0.19812   8.328 5.23e-07 ***\nIndividualN -1.10000    0.19812  -5.552 5.54e-05 ***\nIndividualO -0.10000    0.19812  -0.505 0.621065    \nIndividualP -2.25000    0.19812 -11.357 9.14e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1981 on 15 degrees of freedom\nMultiple R-squared:  0.9949,\tAdjusted R-squared:  0.9895 \nF-statistic: 183.3 on 16 and 15 DF,  p-value: 2.887e-14\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(manos_modelo_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: Length\n           Df  Sum Sq Mean Sq F value    Pr(>F)    \nHand        1   0.451  0.4513  11.497  0.004034 ** \nIndividual 15 114.680  7.6453 194.786 2.089e-14 ***\nResiduals  15   0.589  0.0392                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\nEs cierto que el efecto de *individuo* queda raro en este modelo, pes nos lo reporta en estimadores que tienen sentido como si se tratara de un factor de efectos fijos, es decir que nos interesa decir algo específico sobre esos individuos y ningún otro. Esto obviamente nos es así. El factor individuo es de efectos aleatorios, simplemente que `lm`\\` no prevé esta situación. Los resultados apuntan en la dirección correcta y los valores del factor *Hand* son válidos. Lo podemos manejar razonablemente simplemente recordando que el individuo es de **efectos aleatorios** y que por tanto no tienen mucho sentido, generalmente, hacer referencia a los estimadores puntuales que produce la regresión. Lo que sí tiene interés es la estimación de las varianzas, que permite así corregir e idealmente lograr mayor precisión en la estimación en los tratamientos de interés. En este caso habría que notar que la varianza estimada en el residuo da cuenta tanto de la variación aleatoria que tenemos al medir las unidades experimentales como la del *error de restricción* asociado con las peculiaridades de, en este caso, cada persona que se midió: $\\sigma^{2} + t \\sigma^{2}_{\\delta}$ . La medición de esta varianza combinada, persona + sus peculiaridades = 7.6453, sugiere que es buena idea controlar su efecto. En esto mismos términos la varianza del factor ***hand*** es $\\sigma + t\\sigma\\^{2}_{\\delta} + r\\sigma^{2}_{H}$, lo qe hace válido probar el efecto *fijo* de **hand**.\n\n$$\nF = \\frac {Mean Sq Hand} {Mn Sq error} = \\frac {0.4513}{0.0392} = 11.497\n$$ con 1 y 15 grados de libertad. En **R** tenemos acceso a la distribbución de *F* con la función `qf`que calcula la probabilidad acumulada entre el dato *q* que le doy, así como los grados de libertad asociados.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvarianza <- anova(manos_modelo_3)\n\npf(q = varianza$`F value`[1], df1 = 1, df2 = 15, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.004034071\n```\n\n\n:::\n:::\n\n\n\n\n\nAunque la forma como analizamos estos datos no es la ideal para el caso, podemos ver que produce resultados perfectamente adecuados para la variable de interés, siempre y cuando seamos cocientes de que la función usada aquí en **R**, no maneja apropiadamente los factores de efectos aleatorios y por lo tanto no debemos hacer mayores interpretaciones de los términos correspondientes a esos factores.\n\n## Qué tanto tiempo puede \"correr\" un experimento\n\nCuando Fisher concibió hacer experimentos en la estación experimental de Rothamsted en Inglaterra, recurriendo al auxilio del enfoque estadístico que él y otros investigadores de la época idearon, pensaban a largo plazo. [Encontré este documento que podría ser de su interés](https://repository.cimmyt.org/bitstream/handle/10883/18146/56637_2017_IX%2840%29.pdf?sequence=112&isAllowed=y). La estación experimental tiene disponiible los datos de estos experimentos. Por ejemplo [Este \"dataset\"](https://www.era.rothamsted.ac.uk/dataset/rbk1/01-FISHER1921) son los rendimientos anuales de trigo de \"parcelas selectas\" del experimento de trigo que aún hoy corren en Broadbalk . La serie tiene los datos de 1852-1918, tal y como los usó R.A. Fisher para su artículo de 1921 'Studies in crop variation'.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}