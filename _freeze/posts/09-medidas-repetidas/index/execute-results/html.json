{
  "hash": "1edeb2571c842eea6c0eb79553accde4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Modelos de medidas repetidas\"\nauthor: [\"Miguel Equihua\", \"Elio Lagunes\"]\ndate: \"2024-02-08\"\nlang: es\ndraft: false\ncategories: [clase]\nformat:\n  html:\n    code-fold: true\n---\n\n\n\n\n[![](Picea-sitchensis-Sitka-Spruce-08.jpg){width=\"300\"}](../../presentaciones/09-medidas-repetidas/medidas-repetidas.qmd)\n\n\n\nEl tiempo es una variable problemática en el análisis estadístico, sobre todo por la necesidad de postular el supuesto de independencia entre las observaciones, lo que solemos asegurar aleatorizando las unidades experimentales. Las observaciones arregladas a lo largo del tiempo comúnmente no pueden aleatorizarse, por ejemplo cuando estamos dando seguimiento al crecimiento de un organismo. Por otro lado, también puede ocurrir esta falta de independencia por cercanía geográfica, así que el espacio comparte desafíos estadísticos con el tiempo.\n\n\n# Medidas repetidas (seguimiento a lo largo del tiempo)\n\n## Ejemplo con árboles de *Sitka*\n\nFuente: Venables y Ripley (1999, p.206), tabla Sitka de la biblioteca MASS. Datos de Diggle, Liang y Zeger (1994).\n\nSe trata de mediciones del *tamaño-log* (que se define como el logaritmo de la altura más dos veces el logaritmo del diámetro), de 79 árboles de *Sitka spruce*.\n\nA 54 de ellos se les hizo crecer en cámaras con atmósfera enriquecida con ozono y otros 25 fueron controles. La talla fue medida cinco veces en 1988 a intervalos de aproximadamente un mes (el tiempo se da en días a partir del 1 de enero de 1998). En 1989 se tomaron otras ocho mediciones (que se incluyen en una tabla aparte: Sitka89).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(nlme)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::collapse() masks nlme::collapse()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ dplyr::select()   masks MASS::select()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nsitka88 <- Sitka\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(sitka88)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t395 obs. of  4 variables:\n $ size : num  4.51 4.98 5.41 5.9 6.15 4.24 4.2 4.68 4.92 4.96 ...\n $ Time : num  152 174 201 227 258 152 174 201 227 258 ...\n $ tree : int  1 1 1 1 1 2 2 2 2 2 ...\n $ treat: Factor w/ 2 levels \"control\",\"ozone\": 2 2 2 2 2 2 2 2 2 2 ...\n```\n\n\n:::\n:::\n\n\n\n\nLa estructura de grupos podemos usarla para representar una curva de crecimiento por árbol. Los 79 árboles en los datos \"sitka\" son demasiados para el ejemplo que quiero ilustrar. Mostraré sólo dos árboles: el 64 y 24.\n\n#### Exploración de los datos de *Sitka*\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka88 <-groupedData(size ~ Time | tree, data=sitka88)\nplot(sitka88[sitka88$tree == 64 | sitka88$tree == 24, ])\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n¿Cómo se ven los número de resumen de los datos en general?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformula(sitka88)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nsize ~ Time | tree\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(gsummary(sitka88[, c(\"size\",\"Time\")], groups=sitka88$size, omit=TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     size Time\n2.23 2.23  152\n2.79 2.79  152\n2.84 2.84  152\n2.89 2.89  174\n2.96 2.96  152\n2.99 2.99  152\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot.design(size ~ treat, data=sitka88)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\nPongo una línea de tendencia en la gráfica con la opción geom_smooth. Tengo multiples opciones, ve la ayuda, pero aquí consideré dos opciones *loess* con el parámetro `span = 1`. La otra opción que consideré fue el método *gam*. Esta solución es demandante en cuanto a número de datos necesarios. En este caso tuve que ajustar el parámetro de número de nudos (*knots*), pues la aproximación a una curva suave por el método aditivo generalizado usado, *gam*, requiere por defecto datos para por lo menos calcular 10 nudos y esto no se logra en este conjunto de datos. Usualmente funciona sin mayores problemas cuando se tienen más de 1000 puntos. Para tener una representación un poco más simple opté por eliminar los intervalos de confianza, eso lo controla el parámetro *se*.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(repr.plot.width=12, repr.plot.height=6)\nlibrary(ggplot2)\nggplot(sitka88, aes(x=Time, y=size, color = tree)) + \n       geom_smooth(method = \"loess\", span = 1, formula = y ~ x, se = FALSE, show.legend = FALSE) +\n       geom_point(show.legend = FALSE) + facet_grid(. ~ treat) +\n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sitka88, aes(x=Time, y=size, color = tree)) + \n       geom_smooth(method = \"gam\", span = 1, formula = y ~ s(x, bs = \"cs\", k = 5), \n                   se = FALSE, show.legend = FALSE) +\n       geom_point(show.legend = FALSE) + facet_grid(. ~ treat) +\n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n\nAhora ajusto el modelo completo con el tiempo. Fuerzo a que el tiempo sea tratado como un factor ordenado, lo que junto con la opción de contraste usada ajusta polinomios ortogonales en este caso.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(contrasts=c(\"contr.treatment\", \"contr.poly\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka.lme1 <- lme(fixed = size ~ treat * ordered(Time),\n                  random = ~ 1 | tree,\n                  data = sitka88)\nsummary(sitka.lme1)$tTable\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 Value  Std.Error  DF    t-value       p-value\n(Intercept)                 4.98512000 0.12286970 308 40.5724123 1.332276e-125\ntreatozone                 -0.21115704 0.14861459  77 -1.4208365  1.594013e-01\nordered(Time).L             1.19711183 0.03221011 308 37.1657221 7.430810e-116\nordered(Time).Q            -0.13405824 0.03221011 308 -4.1619932  4.098121e-05\nordered(Time).C            -0.04085663 0.03221011 308 -1.2684413  2.055983e-01\nordered(Time)^4            -0.02729902 0.03221011 308 -0.8475297  3.973580e-01\ntreatozone:ordered(Time).L -0.17856562 0.03895909 308 -4.5834135  6.656627e-06\ntreatozone:ordered(Time).Q -0.02644698 0.03895909 308 -0.6788399  4.977491e-01\ntreatozone:ordered(Time).C -0.01424899 0.03895909 308 -0.3657423  7.148084e-01\ntreatozone:ordered(Time)^4  0.01240293 0.03895909 308  0.3183578  7.504293e-01\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nintervals(sitka.lme1, level = 0.95)$fixed\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 lower        est.       upper\n(Intercept)                 4.74334979  4.98512000  5.22689021\ntreatozone                 -0.50708650 -0.21115704  0.08477242\nordered(Time).L             1.13373214  1.19711183  1.26049153\nordered(Time).Q            -0.19743793 -0.13405824 -0.07067854\nordered(Time).C            -0.10423632 -0.04085663  0.02252307\nordered(Time)^4            -0.09067872 -0.02729902  0.03608067\ntreatozone:ordered(Time).L -0.25522527 -0.17856562 -0.10190597\ntreatozone:ordered(Time).Q -0.10310663 -0.02644698  0.05021266\ntreatozone:ordered(Time).C -0.09090864 -0.01424899  0.06241066\ntreatozone:ordered(Time)^4 -0.06425672  0.01240293  0.08906258\nattr(,\"label\")\n[1] \"Fixed effects:\"\n```\n\n\n:::\n:::\n\n\n\n### Analiizando la interección\n\nNotando la significancia de los términos de interacción: ¿podría simplificar el modelo limitando el ajuste a un efecto lineal de crecimiento que distingue entre los tratamiento? Veamos, calculo un nuevo vector que me permite hacer el ajuste de un efecto lineal a la diferencia entre tratamientos (que es la interacción).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka88$tratGrad <- sitka88$Time * (sitka88$treat==\"ozone\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntapply(sitka88$Time,list(sitka88$treat, sitka88$Time), FUN=mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        152 174 201 227 258\ncontrol 152 174 201 227 258\nozone   152 174 201 227 258\n```\n\n\n:::\n\n```{.r .cell-code}\ntapply(sitka88$tratGrad,list(sitka88$treat, sitka88$Time), FUN=mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        152 174 201 227 258\ncontrol   0   0   0   0   0\nozone   152 174 201 227 258\n```\n\n\n:::\n:::\n\n\n\n\nAhora ajusto un modelo en el que elimino la interacción de tratamiento con tiempo. Al mismo tiempo substituyo este efecto por el modelo con tiempo lineal en interacción con el tratamiento ozono (la variable que acabo de construir).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka.lme2 <- update(sitka.lme1, \n                     fixed = size ~ ordered(Time) + treat + tratGrad)\nsummary(sitka.lme2)$tTable\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                      Value    Std.Error  DF    t-value       p-value\n(Intercept)      4.98512000 0.1228696967 311 40.5724123 2.952779e-126\nordered(Time).L  1.19755089 0.0320437966 311 37.3723158 4.821617e-117\nordered(Time).Q -0.14549447 0.0181029428 311 -8.0370620  1.933996e-14\nordered(Time).C -0.05059644 0.0180459272 311 -2.8037597  5.368534e-03\nordered(Time)^4 -0.01672449 0.0180516171 311 -0.9264818  3.549141e-01\ntreatozone       0.22167749 0.1756140543  77  1.2622992  2.106510e-01\ntratGrad        -0.00213851 0.0004622668 311 -4.6261386  5.473912e-06\n```\n\n\n:::\n:::\n\n\n\n\nEl resumen del ajuste muestra dos criterios que no hemos comentado mayormente antes. Son útiles para comparar y evaluar modelos. Estas medidas son resultado de la búsqueda de alternativas para valorar modelos que no se centre en el famoso valor de *p*.\n\n-   AIC - Criterio de información de Akaike = -2 \\* logVerosimilitud + 2 numParámetros\n-   BIC - Criterio de información bayesiano = -2 \\* logVerosimilitud + numParámetros \\* log(N)\n\nEs bueno contar con ellos para comparar la calidad general de los modelos ajustados, pero no olvides que centrar nuestra atención en los intervalos de confianza es más informativo y potencialmente interesante.\n\nEn cualquier caso, \"entre más pequeño el valor del criterio, mejor\".\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.frame(AICmodelo_red=summary(sitka.lme2)$AIC, AICmodelo_comp=summary(sitka.lme1)$AIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  AICmodelo_red AICmodelo_comp\n1       69.2691       79.90098\n```\n\n\n:::\n\n```{.r .cell-code}\ndata.frame(BICmodelo_red=summary(sitka.lme2)$BIC, BICmodelo_comp=summary(sitka.lme1)$BIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  BICmodelo_red BICmodelo_comp\n1      104.9181       127.3399\n```\n\n\n:::\n:::\n\n\n\n\nTanto el criterio AIC como el BIC sugieren que el modelo reducido es preferible al modelo completo inicial. ¿Qué sugiere la comparación, en devianzas, de ambos modelo?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(sitka.lme1, sitka.lme2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in anova.lme(sitka.lme1, sitka.lme2): fitted objects with different\nfixed effects. REML comparisons are not meaningful.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nsitka.lme1     1 12 79.90098 127.3399 -27.95049                        \nsitka.lme2     2  9 69.26910 104.9181 -25.63455 1 vs 2 4.631882  0.2008\n```\n\n\n:::\n:::\n\n\n\n\nNotese la advertencia que aparece al intentar esta comparación. Para resolverla, hay que volver a ajustar los modelos de interés, pero ahora con el método \"ML\", que si me permite hacer comparaciones entre modelos.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka.lme1.ML <- lme(fixed = size ~ treat * ordered(Time),\n                 random = ~ 1 | tree,\n                 data = sitka88, method=\"ML\")\n\nsitka.lme2.ML <- update(sitka.lme1.ML, \n                     fixed = size ~ ordered(Time) + treat + tratGrad, method=\"ML\")\n```\n:::\n\n\n\n\nComparemos los resultados obtenidos hasta aquí\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(sitka.lme1.ML, sitka.lme2.ML)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              Model df      AIC      BIC    logLik   Test   L.Ratio p-value\nsitka.lme1.ML     1 12 30.94633 78.69296 -3.473163                         \nsitka.lme2.ML     2  9 25.43446 61.24443 -3.717228 1 vs 2 0.4881304  0.9215\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(sitka.lme2.ML)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed-effects model fit by maximum likelihood\n  Data: sitka88 \n       AIC      BIC    logLik\n  25.43446 61.24443 -3.717228\n\nRandom effects:\n Formula: ~1 | tree\n        (Intercept)  Residual\nStdDev:    0.602333 0.1591217\n\nFixed effects:  size ~ ordered(Time) + treat + tratGrad \n                    Value  Std.Error  DF  t-value p-value\n(Intercept)      4.985120 0.12239376 311 40.73018  0.0000\nordered(Time).L  1.197551 0.03207475 311 37.33625  0.0000\nordered(Time).Q -0.145494 0.01812043 311 -8.02931  0.0000\nordered(Time).C -0.050596 0.01806336 311 -2.80105  0.0054\nordered(Time)^4 -0.016724 0.01806906 311 -0.92559  0.3554\ntreatozone       0.221677 0.17517548  77  1.26546  0.2095\ntratGrad        -0.002139 0.00046271 311 -4.62167  0.0000\n Correlation: \n                (Intr) o(T).L o(T).Q o(T).C o(T)^4 tretzn\nordered(Time).L  0.000                                   \nordered(Time).Q  0.000  0.066                            \nordered(Time).C  0.000  0.000  0.000                     \nordered(Time)^4  0.000  0.021  0.002  0.000              \ntreatozone      -0.699  0.442  0.042  0.000  0.013       \ntratGrad         0.000 -0.826 -0.079  0.000 -0.025 -0.535\n\nStandardized Within-Group Residuals:\n         Min           Q1          Med           Q3          Max \n-2.631308932 -0.525058743  0.009619032  0.514425152  5.968135202 \n\nNumber of Observations: 395\nNumber of Groups: 79 \n```\n\n\n:::\n:::\n\n\n\n\n## Selección del polinomio\n\nAhora veamos un poco más de cerca el modelo y veamos si la respuesta muestra una curvatura que pueda ser aproximada entonces por un *polinomio* y en ese caso identificar el *polinomio de menor grado* que podríamos usar.\n\nRecuerden que al utilizar factores ordenados le estamos indicando a **R** que optaremos por **contrastes polinomiales ortogonales**. Otra manera de obtener estos contrastes es con la función `poly`. Para ver como funciona esto usemos este comando los datos de tiempo. Del vector `Time` poly produce cuatro columnas nuevas, que dan cuenta de la tendencia lineal, cuadrática, cúbica, etc., con la peculiaridad de que cada columna es *ortogonal* a las demás.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(poly(sitka88$Time, 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                1           2           3            4\n[1,] -0.067556996  0.05935630 -0.04131435  0.018236996\n[2,] -0.038067831 -0.01959476  0.06928561 -0.059101377\n[3,] -0.001876583 -0.05989079  0.01348825  0.079713367\n[4,]  0.032974248 -0.03974302 -0.07127418 -0.048782834\n[5,]  0.074527162  0.05987226  0.02981468  0.009933848\n[6,] -0.067556996  0.05935630 -0.04131435  0.018236996\n```\n\n\n:::\n:::\n\n\n\n\nEl Modelo 2 que hemos ajustado consumió todos los grados de libertad posible y estimó un polinomio de grado 4. Consideremos sólo el polinomio cúbico.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka.lme3.ML <- lme(fixed = size ~ treat + poly(Time, 3) + tratGrad,\n                 random = ~ 1 | tree,\n                 data = sitka88, method =\"ML\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(sitka.lme3.ML)$tTable\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                     Value    Std.Error  DF    t-value       p-value\n(Intercept)     4.98512000 0.1222363435 312  40.782634 4.608733e-127\ntreatozone      0.22167749 0.1752587841  77   1.264858  2.097370e-01\npoly(Time, 3)1 10.55436327 0.2867893021 312  36.801803 1.551949e-115\npoly(Time, 3)2 -1.90581863 0.1613315870 312 -11.813053  7.256641e-27\npoly(Time, 3)3 -0.25924189 0.1613315870 312  -1.606889  1.090903e-01\ntratGrad       -0.00213851 0.0004649641 312  -4.599303  6.169978e-06\n```\n\n\n:::\n:::\n\n\n\n\nAhora podemos compararlo con el modelo \"2\" que ajustamos antes, para explorar si el nuevo modelo pierde una grado importante de capacidad explicativa.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(sitka.lme2.ML, sitka.lme3.ML)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              Model df      AIC      BIC    logLik   Test L.Ratio p-value\nsitka.lme2.ML     1  9 25.43446 61.24443 -3.717228                       \nsitka.lme3.ML     2  8 27.31449 59.14557 -5.657243 1 vs 2 3.88003  0.0489\n```\n\n\n:::\n:::\n\n\n\n\nEl crecimiento promedio de los árboles a lo largo del tiempo se puede ver así, aunque esto no considera la variación debida a los árboles en lo individual. No obstante veamos el resultado general.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntapply(fitted(sitka.lme3.ML), list(sitka88$treat, sitka88$Time), mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             152      174      201      227      258\ncontrol 4.169687 4.602721 5.075958 5.427362 5.649872\nozone   4.066311 4.452297 4.867795 5.163598 5.319814\n```\n\n\n:::\n:::\n\n\n\n\nMás adecuado es utilizar la función `predict()` para considerar las particularidades del modelo para hacer las predicciones. Estos resultados los pondremos en una gráfica para ver de mejor manera los resultados.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka88$ajus <- predict(sitka.lme3.ML)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sitka88, aes(x=Time, y=ajus, color = tree)) + \n       geom_point(show.legend = FALSE) + facet_grid(. ~ treat) +\n       geom_line(show.legend = FALSE) + \n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Componente aleatorio\n\nPodemos ahora explorar como mejorar la modelación de los componentes aleatorios en este modelo.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nVarCorr(sitka.lme1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntree = pdLogChol(1) \n            Variance   StdDev   \n(Intercept) 0.37223660 0.6101120\nResidual    0.02593727 0.1610505\n```\n\n\n:::\n:::\n\n\n\n\nLos modelos pueden incorporar una estructura de modelación de los patrones de correlación entre las observaciones. En este caso derivadas del hecho de que las mediciones se realizan a lo largo del tiempo, en intervalos relativamente cortos, sobre el mismo sujeto. Haremos esto aquí solo para ejemplificar el tema, que es amplio. Mi recomendación es más bien recurrir a la literatura existente para profundizar en el tema. Nótese que para la comparación de modelos en donde no estamos cambiando los componentes fijo, puede hacerse aún cuando el método de ajuste sea el *REML*. Usamos una opción del patrón de correlación que estamos asumiendo mediante la opción `cor` que recibe una estructura que da cuenta del patrón de correlación que se asume afecta a la forma como se producen las observaciones. En este caso optamos por un proceso de *autocorrelación de orden 1* en las observaciones con correlación de 70%, derivado de medir a lo largo del tiempo cada árbol. Esto es lo que hace la función `corCAR1`, sobre la que pueden encontrar más información en la ayuda de **R**.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka.lme4 <- lme(size~ treat * ordered(Time), random = ~ 1 | tree,\n                  data = sitka88, corr=corCAR1(0.7, ~ Time | tree))\n```\n:::\n\n\n\n\nVeamos como cambian los estadísticos de los modelos. Comparemos el modelo completo inicial, contra el completo considerando la nueva información sobre la correlación que hemos agregado en el modelo 4.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(sitka.lme1,sitka.lme4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           Model df       AIC      BIC    logLik   Test  L.Ratio p-value\nsitka.lme1     1 12  79.90098 127.3399 -27.95049                        \nsitka.lme4     2 13 -63.17167 -11.7795  44.58583 1 vs 2 145.0727  <.0001\n```\n\n\n:::\n:::\n\n\n\n\nSe ve raro que haya [AIC y BIC negativos](https://www.statology.org/negative-aic/), pero pasa, sí los consideraríamos como valores más pequeños que los positivos, así que aquí, el modelo 4 parece tener un ajuste bastante mejor que el 1.\n\n¿cómo se ve el modelo ajustado finalmente?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(sitka.lme4)$tTable\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 Value  Std.Error  DF    t-value       p-value\n(Intercept)                 4.98512000 0.12635223 308 39.4541523 1.827148e-122\ntreatozone                 -0.21115704 0.15282682  77 -1.3816753  1.710673e-01\nordered(Time).L             1.19711183 0.04907128 308 24.3953674  6.282539e-74\nordered(Time).Q            -0.13405824 0.02642497 308 -5.0731653  6.774439e-07\nordered(Time).C            -0.04085663 0.01978964 308 -2.0645467  3.980280e-02\nordered(Time)^4            -0.02729902 0.01672573 308 -1.6321568  1.036684e-01\ntreatozone:ordered(Time).L -0.17856562 0.05935318 308 -3.0085264  2.841806e-03\ntreatozone:ordered(Time).Q -0.02644698 0.03196179 308 -0.8274562  4.086192e-01\ntreatozone:ordered(Time).C -0.01424899 0.02393616 308 -0.5952914  5.520859e-01\ntreatozone:ordered(Time)^4  0.01240293 0.02023028 308  0.6130875  5.402709e-01\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(sitka.lme1)$tTable\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 Value  Std.Error  DF    t-value       p-value\n(Intercept)                 4.98512000 0.12286970 308 40.5724123 1.332276e-125\ntreatozone                 -0.21115704 0.14861459  77 -1.4208365  1.594013e-01\nordered(Time).L             1.19711183 0.03221011 308 37.1657221 7.430810e-116\nordered(Time).Q            -0.13405824 0.03221011 308 -4.1619932  4.098121e-05\nordered(Time).C            -0.04085663 0.03221011 308 -1.2684413  2.055983e-01\nordered(Time)^4            -0.02729902 0.03221011 308 -0.8475297  3.973580e-01\ntreatozone:ordered(Time).L -0.17856562 0.03895909 308 -4.5834135  6.656627e-06\ntreatozone:ordered(Time).Q -0.02644698 0.03895909 308 -0.6788399  4.977491e-01\ntreatozone:ordered(Time).C -0.01424899 0.03895909 308 -0.3657423  7.148084e-01\ntreatozone:ordered(Time)^4  0.01240293 0.03895909 308  0.3183578  7.504293e-01\n```\n\n\n:::\n:::\n\n\n\n\nAunque hay obviamente una importante correlaciónn entre observaciones, el efecto de considerar esto en el modelo es mínimo en términos de los valores de los coeficientes, aunque la significación valorada en términos de *p* cambia un poco, pero nada que nos haga modificar la apreciación del modelo. No parece valer la pena incorporar este aspecto de autocorrelación en el ajuste final, si nos atenemos a preferir el modelo más simple. Por otro lado, el asunto de considerar un efecto de autocorrelación en las observaciones parece exigir ser considerado. Tomemos este último camino\n\nLos intervalos de confianza de los coeficientes del modelo 4 son estos:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintervals(sitka.lme4, which = \"fixed\", level = 0.95)$fixed\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 lower        est.        upper\n(Intercept)                 4.73649723  4.98512000  5.233742772\ntreatozone                 -0.51547411 -0.21115704  0.093160032\nordered(Time).L             1.10055448  1.19711183  1.293669187\nordered(Time).Q            -0.18605455 -0.13405824 -0.082061932\nordered(Time).C            -0.07979661 -0.04085663 -0.001916640\nordered(Time)^4            -0.06021018 -0.02729902  0.005612139\ntreatozone:ordered(Time).L -0.29535464 -0.17856562 -0.061776597\ntreatozone:ordered(Time).Q -0.08933808 -0.02644698  0.036444111\ntreatozone:ordered(Time).C -0.06134807 -0.01424899  0.032850096\ntreatozone:ordered(Time)^4 -0.02740411  0.01240293  0.052209970\nattr(,\"label\")\n[1] \"Fixed effects:\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka.fin <- aggregate(list(ajustado=fitted(sitka.lme4)), \n                       list(tiempo=sitka88$Time, trat=sitka88$treat), FUN=mean)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsitka.fin$tiempo <- as.numeric(sitka.fin$tiempo)\n```\n:::\n\n\n\n\nUna gráfica de los resultados podría ser así. Ilustra la regresión obtenida para cada tratamiento y añado los puntos observados ( para que se vean un poco mejor use el *geoma* \"jitter\" que grafica los puntos pero procurando que no se sobrepongan. Le pedí que lo hicieran en \"bandas\" de ancho 2.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sitka.fin, aes(x=tiempo, y=ajustado, color = trat)) + \n       geom_line(show.legend = TRUE) + \n       geom_point(show.legend = FALSE) + \n       xlab(label = \"tamaño-log\") +\n       ylab(label = \"tiempo (días)\") + \n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20)) +\n\n       # componente que agrega los datos a la gráfica\n       geom_jitter(data = sitka88, width = 2, \n                   mapping = aes(x = Time, y = size, color = treat)) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n\nConstruir los intervalos de confianza a partir del modelo de efectos mixtos puede ser un poco más elaborado, así que a continuación muestro como pueden hacerse. Una posibilidad es usar la función `intervals`con la opción *which = \"fixed\"* para recuperar los resultados que implica sólo a los componentes de efectos fijos del modelo, que son los que se involucran en la predicción (los aleatorios participan en las varianzas).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse, warn.conflicts = FALSE)\nsitka_intconf <- tibble(Time = sitka88$Time, treat = sitka88$treat)\nsitka_intconf <- sitka_intconf %>% add_column(ajus = fitted(sitka.lme4, level = 0))\nhead(sitka_intconf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n   Time treat  ajus\n  <dbl> <fct> <dbl>\n1   152 ozone  4.06\n2   174 ozone  4.47\n3   201 ozone  4.85\n4   227 ozone  5.18\n5   258 ozone  5.31\n6   152 ozone  4.06\n```\n\n\n:::\n:::\n\n\n\n\nNecesitaremos la matriz de diseño para calcular los intervalos de confianza asociados con el mmodelo.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDesignmat <- model.matrix(eval(eval(sitka.lme4$call$fixed)[-2]), \n                          sitka_intconf[-ncol(sitka_intconf)])\n```\n:::\n\n\n\n\nAhora calculamos los errores estándar de las predicciones. La matriz diseño contiene las variables indicadoras de todos los términos en el modelo. Al multiplicarla por la matriz de varianzas y covarianzas del modelo (la que está en el componente `sitka.lme4$varFix` del modelo ajustado), produce los estimadores de varianza requeridos\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredvar <- diag(Designmat %*% sitka.lme4$varFix %*% t(Designmat))\nsitka_intconf$SE <- sqrt(predvar) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sitka_intconf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n   Time treat  ajus     SE\n  <dbl> <fct> <dbl>  <dbl>\n1   152 ozone  4.06 0.0880\n2   174 ozone  4.47 0.0880\n3   201 ozone  4.85 0.0880\n4   227 ozone  5.18 0.0880\n5   258 ozone  5.31 0.0880\n6   152 ozone  4.06 0.0880\n```\n\n\n:::\n:::\n\n\n\n\nSolo resta agregar las bandas de confianza en torno a la egresión. Esto lo haré con el *geoma* \"ribbon\" de **ggplot2**. Esta será una gráfica compleja que se elabora a partir de tres tablas de datos.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(sitka.fin, aes(x=tiempo, y=ajustado, color = trat)) + \n       geom_line(show.legend = TRUE) + \n\n       # Etiquetas y formato de despliegue\n       xlab(label = \"tamaño-log\") +\n       ylab(label = \"tiempo (días)\") + \n       theme(strip.background = element_rect(fill=\"#ffe5cc\"),\n             text = element_text(size = 20)) +\n\n       # bandas de confianza\n       geom_ribbon(data = sitka_intconf, aes(x = Time, y = ajus, color = treat,\n                                             ymin = ajus - 2 * SE,\n                                             ymax = ajus + 2 * SE),\n                   alpha=0.2, fill = \"blue\") +       \n\n       # componente que agrega los datos a la gráfica\n       geom_jitter(data = sitka88, width = 2, \n                   mapping = aes(x = Time, y = size, color = treat)) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}